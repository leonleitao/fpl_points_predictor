{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import get_data\n",
    "import feature_engineering as fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step was to input the three dataframes using the functions defined in **get_data.py**\n",
    "\n",
    "1. **players**: Data for each player (team, position, etc) with some aggregate statistics (total point, total goals, etc)\n",
    "2. **gws**: Data for each player for each gameweek. It includes detailed information such as the number of goals, assists, points,etc for a single gameweek.\n",
    "3. **fixtures**: All the fixtures for the season\n",
    "\n",
    "I then got the current gameweek number using the gws dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players=get_data.get_player_data()\n",
    "gws=get_data.get_gameweek_data()\n",
    "fixtures=get_data.get_fixtures()\n",
    "\n",
    "# Getting the current gameweek number\n",
    "current_gw=max(set(gws['round']))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*players* has a lot of columns that are not available for each gameweek and so we cannot use them in making predictions. So I filtered the dataset to only include basic information such as **id, first_name, second_name, team, and position**\n",
    "\n",
    "Similarly for *fixtures*, I filtered to all the previous fixtures plus the current gameweek fixtures and only kept three columns: ** event, team_a (away team), team_h (home team)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering player data to only required columns\n",
    "players=players[['id_x','first_name','second_name','team','position']]\n",
    "# test=test[(test['id_x']==531)|(test['id_x']==390)|(test['id_x']==569)]\n",
    "\n",
    "# Filtering the fixtures upto the current list of fixtures\n",
    "fixtures=fixtures[['event','team_a','team_h']]\n",
    "fixtures=fixtures[fixtures['event']<= current_gw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got all the home and away fixtures for each player by merging *players* and *fixtures* and then concatenated the two dataframes to create a single dataframe with all past and present fixtures (fixtures for the current gameweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home fixtures for each player\n",
    "home=pd.merge(players,fixtures,left_on='team',right_on='team_h')\n",
    "# Away fixxtures for each player\n",
    "away=pd.merge(players,fixtures,left_on='team',right_on='team_a')\n",
    "# Concatenating home and away fixtures to a single dataframe\n",
    "df=pd.concat([home,away]).sort_values('event').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a binary feature called **is_home** to denote whether player was playing at his home stadium and another feature **opposition team** that includes the team number of the opponent. I then dropped the **team_a** and **team_h** columns as the data was already contained in the two new features that were created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a binary feature for home fixtures\n",
    "df['is_home']=np.where(df['team']==df['team_h'],1,0)\n",
    "# Adding a feature for the opposition team team number\n",
    "df['opposition_team']=np.where(df['is_home'],df['team_a'],df['team_h'])\n",
    "df=df.drop(['team_a','team_h'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined a list of features from *gws* that would be useful in predicting points for the current gameweeek. Since this information wouldn't be available at the time of prediction, I created features that included the average values of these features for all gameweeeks before or n gameweeks before. \n",
    "\n",
    "For example, for each player I include information such as the average number of goals per game, average number of assists per game, etc. I also want to take into account the current form of the player, so I also include features such as average goals in the last n games.\n",
    "\n",
    "I added these features with the help of a function called ***get_average_stats*** located in **feature_enginnering.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stats from gws dataset that would be useful\n",
    "cols=['minutes','goals_scored', 'assists', 'clean_sheets', 'goals_conceded',\n",
    "      'yellow_cards','red_cards', 'saves', 'bonus', 'bps', 'influence', 'creativity',\n",
    "      'threat', 'ict_index', 'value']\n",
    "target_col=['total_points',]\n",
    "# Merging the current dataframe with gws to include the above information\n",
    "df=pd.merge(df,gws[['element','round']+cols+target_col],left_on=['id_x','event'],right_on=['element','round'],how='left').drop(['element','round'],axis=1)\n",
    "# Removing NA values that result from the merge. These NA's are because of new transfers as the player did not have scores/points for previous gameweeks.\n",
    "df=df[~((df['event']!=current_gw)&(df['total_points'].isna()))]\n",
    "# Get the average stats for each player for past gameweeks as well as average for last 2 gameweeks\n",
    "df=df.groupby('id_x').apply(lambda x: fe.get_average_stats(x,cols+target_col))\n",
    "df=df.groupby('id_x').apply(lambda x: fe.get_average_stats(x,cols+target_col,2))\n",
    "# Drop these columns as they cannot be used for new predictions\n",
    "df=df.drop(cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final dataset: \\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List of columns:\\n\")\n",
    "_=[print(col) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('fpl')",
   "metadata": {
    "interpreter": {
     "hash": "785da5d47e9d68d859abbfcfd88431f2f86c474bdc9d3f0972b8594223a71292"
    }
   },
   "name": "Python 3.7.9 64-bit ('fpl')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
